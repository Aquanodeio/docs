---
title: OSS Models
description: Open source models available on Aquanode
---

Aquanode provides a curated catalog of **open-source models** that you can deploy instantly via the console. These models cover text, code, vision, and generative tasks, powered by **vLLM** and **Ollama runtimes** for efficient inference.

---

## Featured Models

- **Flux.1-Dev** â†’ Fluxâ€™s developer model optimized for fast deployment.  
- **Flux.1-Kontext-dev** â†’ Fluxâ€™s context-aware model for multimodal tasks.  
- **Flux.1-Krea-dev** â†’ Fluxâ€™s creative-focused model for generative use cases.  

---

## Text Models

- **DeepSeek-R1 1.5B / 8B / 14B / 32B / 70B**  
  DeepSeekâ€™s reasoning-focused models in multiple parameter sizes.  

- **Gemma / Gemma 2**  
  Googleâ€™s lightweight language models via Ollama.  

- **Llama 3.1 / 3.2 / 3.3**  
  Metaâ€™s Llama 3.x family via Ollama.  

- **Phi / Phi 3 / Phi 3.5**  
  Microsoftâ€™s compact and efficient Phi series via Ollama.  

- **Qwen 2.5**  
  Alibabaâ€™s Qwen 2.5 model via Ollama.  

- **OpenAI OSS 20B / 120B**  
  OpenAIâ€™s GPT-OSS open models via vLLM.  

---

## Coding Models

- **Qwen 2.5 Coder**  
  Specialized variant of Qwen 2.5 optimized for coding and programming tasks.  

---

## Vision & Multimodal Models

- **Qwen 2.5 VL**  
  Vision-language model (text + image) from Alibaba, served via vLLM.  

- **Flux.1-Kontext-dev**  
  Multimodal image-text-to-image model for contextual generative tasks.  

- **Flux.1-Krea-dev**  
  Multimodal model optimized for creative workflows.  

---

## Text-to-Image Models

- **Flux.1-Schnell**  
  High-speed text-to-image model optimized for fast deployment.  

- **Flux.1-Dev**  
  Flux Dev model available for text-to-image generation.  

- **CogView4-6B**  
  CogView4 generative model for high-quality text-to-image inference.  

---

## Usage Notes

- All models are hosted with **Aquanodeâ€™s Inference APIs**, accessible with your API key.  
- Models can be deployed via [Model Pipelines Console](https://console.aquanode.io/workloads/model-pipeline/serverless-vllm).  
- Select GPU resources based on model size (e.g., larger models like DeepSeek 70B require H100/B200).  

---

ðŸŽ‰ With Aquanodeâ€™s OSS catalog, you can quickly deploy **LLMs, multimodal models, and generative pipelines** without worrying about infrastructure.

